{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TruthLens Capstone — ISOT Fake News Detection with MLflow\n",
        "\n",
        "**Neoversity DS&DA | TruthLens MVP**  \n",
        "Pipeline: load ISOT dataset → EDA → TF-IDF + multiple classifiers → MLflow tracking → comparison & best model.\n",
        "\n",
        "Runs in Jupyter (Windows/WSL) and Colab. No `%%bash` — Python-only setup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup (Python-only, Colab & local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def ensure_packages():\n",
        "    packages = [\"pandas\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"mlflow\", \"joblib\", \"requests\"]\n",
        "    for p in packages:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", p])\n",
        "\n",
        "ensure_packages()\n",
        "Path(\"data/isot\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"artifacts\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"mlruns\").mkdir(parents=True, exist_ok=True)\n",
        "print(\"OK: packages & folders ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load ISOT dataset (UVic fallback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "UVIC_ZIP_URL = \"https://onlineacademiccommunity.uvic.ca/isot/wp-content/uploads/sites/7295/2023/03/News-_dataset.zip\"\n",
        "\n",
        "def _find_case_insensitive(folder: Path, filename: str):\n",
        "    if not folder.exists(): return None\n",
        "    target = filename.lower()\n",
        "    for p in folder.iterdir():\n",
        "        if p.is_file() and p.name.lower() == target: return p\n",
        "    return None\n",
        "\n",
        "def _download_and_unzip_uvic(dest_dir: Path):\n",
        "    import io, zipfile, requests\n",
        "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "    r = requests.get(UVIC_ZIP_URL, timeout=180)\n",
        "    r.raise_for_status()\n",
        "    with zipfile.ZipFile(io.BytesIO(r.content)) as zf:\n",
        "        zf.extractall(dest_dir)\n",
        "\n",
        "def load_isot_dataset(base_dir: str = \"data/isot\", auto_download_uvic: bool = True) -> pd.DataFrame:\n",
        "    base = Path(base_dir)\n",
        "    candidates = [base, Path(\"data\") / \"isot\", Path(\".\")]\n",
        "    true_path = fake_path = None\n",
        "    for folder in candidates:\n",
        "        tp = _find_case_insensitive(folder, \"True.csv\")\n",
        "        fp = _find_case_insensitive(folder, \"Fake.csv\")\n",
        "        if tp and fp: true_path, fake_path = tp, fp; break\n",
        "    if (true_path is None or fake_path is None) and auto_download_uvic:\n",
        "        _download_and_unzip_uvic(base)\n",
        "        true_path = _find_case_insensitive(base, \"True.csv\")\n",
        "        fake_path = _find_case_insensitive(base, \"Fake.csv\")\n",
        "    if true_path is None or fake_path is None:\n",
        "        raise FileNotFoundError(\"True.csv/Fake.csv not found. Put in data/isot/ or enable auto_download.\")\n",
        "    true_df = pd.read_csv(true_path)\n",
        "    fake_df = pd.read_csv(fake_path)\n",
        "    true_df.columns = [c.strip().lower() for c in true_df.columns]\n",
        "    fake_df.columns = [c.strip().lower() for c in fake_df.columns]\n",
        "    true_df[\"label\"] = 1\n",
        "    fake_df[\"label\"] = 0\n",
        "    df = pd.concat([true_df, fake_df], ignore_index=True)\n",
        "    if \"text\" not in df.columns: raise ValueError(\"Expected column 'text'.\")\n",
        "    title_part = df[\"title\"].fillna(\"\").astype(str) if \"title\" in df.columns else \"\"\n",
        "    df[\"text\"] = (title_part + \" \" + df[\"text\"].fillna(\"\").astype(str)).str.strip()\n",
        "    df = df[df[\"text\"].str.len() > 0].drop_duplicates(subset=[\"text\", \"label\"]).reset_index(drop=True)\n",
        "    print(f\"Loaded: {df.shape[0]} rows | labels: {df['label'].value_counts().to_dict()}\")\n",
        "    return df\n",
        "\n",
        "df = load_isot_dataset(base_dir=\"data/isot\", auto_download_uvic=True)\n",
        "X = df[\"text\"]\n",
        "y = df[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) EDA — class balance & text length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "df[\"label\"].value_counts().plot(kind=\"bar\", ax=axes[0], title=\"Class balance (1=Real, 0=Fake)\")\n",
        "df[\"text\"].str.len().hist(ax=axes[1], bins=50, title=\"Text length distribution\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"artifacts/eda.png\", dpi=100)\n",
        "plt.show()\n",
        "print(\"Saved: artifacts/eda.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train multiple models with MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "mlflow.set_tracking_uri(\"file://\" + str(Path(\"mlruns\").resolve()))\n",
        "mlflow.set_experiment(\"truthlens-fake-news-isot\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "vectorizer = TfidfVectorizer(max_features=20_000, ngram_range=(1, 2), min_df=2)\n",
        "X_train_tf = vectorizer.fit_transform(X_train)\n",
        "X_test_tf = vectorizer.transform(X_test)\n",
        "\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=500, random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"MultinomialNB\": MultinomialNB(),\n",
        "}\n",
        "\n",
        "metrics_list = []\n",
        "best_f1, best_name, best_pipe = 0, None, None\n",
        "\n",
        "for name, clf in models.items():\n",
        "    with mlflow.start_run(run_name=name):\n",
        "        clf.fit(X_train_tf, y_train)\n",
        "        y_pred = clf.predict(X_test_tf)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "        mlflow.log_params({\"model\": name, \"vectorizer\": \"TfidfVectorizer\", \"max_features\": 20000})\n",
        "        mlflow.log_metrics({\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1})\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        mlflow.log_dict({\"confusion_matrix\": cm.tolist()}, \"confusion_matrix.json\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_name = f1, name\n",
        "            best_pipe = {\"vectorizer\": vectorizer, \"model\": clf}\n",
        "        metrics_list.append({\"model\": name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1})\n",
        "        print(f\"{name}: accuracy={acc:.4f} f1={f1:.4f}\")\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_list)\n",
        "joblib.dump(best_pipe, \"artifacts/best_model.joblib\")\n",
        "with open(\"artifacts/best_run_summary.json\", \"w\") as f:\n",
        "    json.dump({\"best_model\": best_name, \"best_f1\": float(best_f1), \"metrics\": metrics_list}, f, indent=2)\n",
        "print(f\"\\nBest model: {best_name} (f1={best_f1:.4f}). Saved: artifacts/best_model.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Comparative performance (Capstone requirement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_pct = metrics_df.copy()\n",
        "for col in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
        "    metrics_pct[col] = (metrics_pct[col] * 100).round(2)\n",
        "display(metrics_pct.sort_values(\"f1\", ascending=False))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics_pct[\"model\"], metrics_pct[\"f1\"])\n",
        "plt.ylabel(\"F1-score (%)\")\n",
        "plt.title(\"TruthLens — Model F1 comparison (ISOT)\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"artifacts/model_comparison.png\", dpi=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Inference demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = joblib.load(\"artifacts/best_model.joblib\")\n",
        "examples = [\n",
        "    \"Breaking: the government confirmed new economic measures today.\",\n",
        "    \"Shocking secret cure doctors don't want you to know!!!\",\n",
        "    \"Company reports quarterly earnings with moderate growth.\",\n",
        "]\n",
        "X_ex = pipe[\"vectorizer\"].transform(examples)\n",
        "pred = pipe[\"model\"].predict(X_ex)\n",
        "for t, p in zip(examples, pred):\n",
        "    lbl = 'Real' if p == 1 else 'Fake'\n",
        "    print(f\"{p} ({lbl}): {t[:60]}...\")\n",
        "print(\"\\nLabel: 1=Real, 0=Fake\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**TruthLens Capstone** — MLflow UI: `mlflow ui --backend-store-uri ./mlruns`  \n",
        "Best model and metrics: `artifacts/best_model.joblib`, `artifacts/best_run_summary.json`.\n",
        "\n",
        "**Копіювання в репо TruthLens (WSL):**  \n",
        "`cp \"цій_шлях/notebooks_01_isot_fake_news_detection_mlflow.ipynb\" ~/TruthLens/notebooks/`  \n",
        "Потім: `git add notebooks/ && git commit -m \"feat: add ML fake news notebook\" && git push origin main`  \n",
        "**Jupyter:** `pip install jupyter mlflow` → `jupyter notebook notebooks/notebooks_01_isot_fake_news_detection_mlflow.ipynb`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
